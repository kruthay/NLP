{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 410,
     "status": "ok",
     "timestamp": 1678919272860,
     "user": {
      "displayName": "Kruthay Reddy",
      "userId": "05785491489446510821"
     },
     "user_tz": 240
    },
    "id": "c_0SdO4zK2Kq"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import sklearn\n",
    "from sklearn.metrics import cohen_kappa_score as kappa\n",
    "from sklearn.metrics import accuracy_score as accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 620,
     "status": "ok",
     "timestamp": 1678919273478,
     "user": {
      "displayName": "Kruthay Reddy",
      "userId": "05785491489446510821"
     },
     "user_tz": 240
    },
    "id": "UD7yvkwgy82S",
    "outputId": "13d10405-f193-4604-b629-17cc413f2e92"
   },
   "outputs": [],
   "source": [
    "### WRITE CODE TO LOAD ANNOTATIONS AND \n",
    "df = pd.read_table('DataFiles/augmented_data.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1678919273478,
     "user": {
      "displayName": "Kruthay Reddy",
      "userId": "05785491489446510821"
     },
     "user_tz": 240
    },
    "id": "edOh9ooiIW1B",
    "outputId": "b0a7de83-6c0f-471c-a0d5-165e8717681e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found device: Tesla T4, n_gpu: 1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Confirm that the GPU is detected\n",
    "\n",
    "assert torch.cuda.is_available()\n",
    "\n",
    "# Get the GPU device name.\n",
    "device_name = torch.cuda.get_device_name()\n",
    "n_gpu = torch.cuda.device_count()\n",
    "print(f\"Found device: {device_name}, n_gpu: {n_gpu}\")\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xrvH7xx9LnMC"
   },
   "source": [
    "## Installing Hugging Face's Transformers library\n",
    "We will use Hugging Face's Transformers (https://github.com/huggingface/transformers), an open-source library that provides general-purpose architectures for natural language understanding and generation with a collection of various pretrained models made by the NLP community."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8911,
     "status": "ok",
     "timestamp": 1678919282387,
     "user": {
      "displayName": "Kruthay Reddy",
      "userId": "05785491489446510821"
     },
     "user_tz": 240
    },
    "id": "gtqS2e5fxpqa",
    "outputId": "0b622c3b-7f72-4284-dacf-ce25f4933184"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (4.27.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.6.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install -U -q PyDrive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-8XIL7wPovVX"
   },
   "source": [
    "The cell below imports some helper functions we wrote to demonstrate the task on the sample dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1678919282388,
     "user": {
      "displayName": "Kruthay Reddy",
      "userId": "05785491489446510821"
     },
     "user_tz": 240
    },
    "id": "ZevgzNCcLmVO"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "from torch.utils.data import TensorDataset, random_split\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "import sys\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "def tokenize_and_format(sentences):\n",
    "  tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-uncased', do_lower_case=True)\n",
    "\n",
    "  # Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "  input_ids = []\n",
    "  attention_masks = []\n",
    "\n",
    "  # For every sentence...\n",
    "  for sentence in sentences:\n",
    "      # `encode_plus` will:\n",
    "      #   (1) Tokenize the sentence.\n",
    "      #   (2) Prepend the `[CLS]` token to the start.\n",
    "      #   (3) Append the `[SEP]` token to the end.\n",
    "      #   (4) Map tokens to their IDs.\n",
    "      #   (5) Pad or truncate the sentence to `max_length`\n",
    "      #   (6) Create attention masks for [PAD] tokens.\n",
    "      encoded_dict = tokenizer.encode_plus(\n",
    "                          sentence,                      # Sentence to encode.\n",
    "                          add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                          max_length = 64,           # Pad & truncate all sentences.\n",
    "                          padding = 'max_length',\n",
    "                          truncation = True,\n",
    "                          return_attention_mask = True,   # Construct attn. masks.\n",
    "                          return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                    )\n",
    "\n",
    "      # Add the encoded sentence to the list.\n",
    "      input_ids.append(encoded_dict['input_ids'])\n",
    "\n",
    "      # And its attention mask (simply differentiates padding from non-padding).\n",
    "      attention_masks.append(encoded_dict['attention_mask'])\n",
    "  return input_ids, attention_masks\n",
    "\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 53979,
     "status": "ok",
     "timestamp": 1678919336363,
     "user": {
      "displayName": "Kruthay Reddy",
      "userId": "05785491489446510821"
     },
     "user_tz": 240
    },
    "id": "YGhkeLQlNNr8",
    "outputId": "23234d22-8c5c-42e0-eb20-d0c41b6b502b"
   },
   "outputs": [],
   "source": [
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "texts = df.sentence.values\n",
    "labels = df.label_ID.values\n",
    "labels2 = df.label_ID2.values\n",
    "\n",
    "input_ids, attention_masks = tokenize_and_format(texts)\n",
    "\n",
    "\n",
    "label_list = []\n",
    "for l,m in zip(labels, labels2):\n",
    "  label_array = np.zeros(len(set(labels)))\n",
    "  label_array[int(l)-1] += 0.5\n",
    "  label_array[int(m)-1] += 0.5\n",
    "  label_list.append(label_array)\n",
    "\n",
    "\n",
    "\n",
    "# Convert the lists into tensors.\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(np.array(label_list))\n",
    "\n",
    "# Print sentence 0, now as a list of IDs.\n",
    "print('Original: ', texts[0])\n",
    "print('Token IDs:', input_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1678919336363,
     "user": {
      "displayName": "Kruthay Reddy",
      "userId": "05785491489446510821"
     },
     "user_tz": 240
    },
    "id": "kGgeZ3M0UWs0"
   },
   "outputs": [],
   "source": [
    "total = len(df)\n",
    "num_train = int(len(df)*0.8)\n",
    "num_val = int(len(df)*0.1)\n",
    "num_test = total - num_val\n",
    "\n",
    "# make lists of 3-tuples (already shuffled the dataframe in cell above)\n",
    "\n",
    "train_set = [(input_ids[i], attention_masks[i], labels[i]) for i in range(num_train)]\n",
    "val_set = [(input_ids[i], attention_masks[i], labels[i]) for i in range(num_train, num_val)]\n",
    "test_set = [(input_ids[i], attention_masks[i], labels[i]) for i in range(num_val, total)]\n",
    "\n",
    "\n",
    "train_text = [texts[i] for i in range(num_train)]\n",
    "val_text = [texts_test[i] for i in range(num_train, num_val)]\n",
    "test_text = [texts_test[i] for i in range(num_val, total)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 176,
     "referenced_widgets": [
      "9803d2efa3d24145b5dcb92a0301cbe4",
      "195b7adc0d48404983152b92b30e45c9",
      "cca5415315f34a19a0157289596fd009",
      "cc6b7430b36c4fe59497a786f9b32aef",
      "910bce19900f4576b4e2c828330bc14c",
      "b3f3e14252604a8cba83f1f0baadae77",
      "a4a42affa4894e29ab8a7b877d4f4482",
      "3b276e107e7b4b529eddde887626d9e0",
      "af94a1207256473cb226ba419c223ccb",
      "fff9297d1c894764bf30a6b32f40b0d6",
      "f5766afc8e7043d5a7bde77580d0e4ea"
     ]
    },
    "executionInfo": {
     "elapsed": 21399,
     "status": "ok",
     "timestamp": 1678919357756,
     "user": {
      "displayName": "Kruthay Reddy",
      "userId": "05785491489446510821"
     },
     "user_tz": 240
    },
    "id": "lPo640_ZlEPK",
    "outputId": "04d5b9f2-398d-4bf8-d779-0a77ce96f66b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9803d2efa3d24145b5dcb92a0301cbe4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/672M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-multilingual-uncased\", # Use the 12-layer English BERT model, with an uncased vocab.\n",
    "    num_labels = 15, # The number of output labels.   \n",
    "    output_attentions = False, # Whether the model returns attentions weights.\n",
    "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
    ")\n",
    "\n",
    "model.config.hidden_dropout_prob = 0.2\n",
    "\n",
    "# Tell pytorch to run this model on the GPU.\n",
    "model.cuda()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1678919357757,
     "user": {
      "displayName": "Kruthay Reddy",
      "userId": "05785491489446510821"
     },
     "user_tz": 240
    },
    "id": "Dd2JdC6IletV",
    "outputId": "4cb2cfcd-84aa-4204-be7a-5c28198943bb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_size = 32\n",
    "optimizer = AdamW(model.parameters(), lr = 5e-5) #with default values of learning rate and epsilon value\n",
    "epochs = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1678919357757,
     "user": {
      "displayName": "Kruthay Reddy",
      "userId": "05785491489446510821"
     },
     "user_tz": 240
    },
    "id": "O_Mzr-kd5RaY"
   },
   "outputs": [],
   "source": [
    "def validation(val_set):\n",
    "    # Put the model in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables \n",
    "    total_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "\n",
    "    num_batches = int(len(val_set)/batch_size) + 1\n",
    "\n",
    "    total_correct = 0\n",
    "    incorrect_values = []\n",
    "    for i in range(num_batches):\n",
    "\n",
    "      end_index = min(batch_size * (i+1), len(val_set))\n",
    "\n",
    "      batch = val_set[i*batch_size:end_index]\n",
    "      \n",
    "      if len(batch) == 0: continue\n",
    "\n",
    "      input_id_tensors = torch.stack([data[0] for data in batch])\n",
    "      input_mask_tensors = torch.stack([data[1] for data in batch])\n",
    "      label_tensors = torch.stack([data[2] for data in batch])\n",
    "      \n",
    "      # Move tensors to the GPU\n",
    "      b_input_ids = input_id_tensors.to(device)\n",
    "      b_input_mask = input_mask_tensors.to(device)\n",
    "      b_labels = label_tensors.to(device)\n",
    "        \n",
    "      # Tell pytorch not to bother with constructing the compute graph during\n",
    "      # the forward pass, since this is only needed for backprop (training).\n",
    "      with torch.no_grad():        \n",
    "\n",
    "        # Forward pass, calculate logit predictions.\n",
    "        outputs = model(b_input_ids, \n",
    "                                token_type_ids=None, \n",
    "                                attention_mask=b_input_mask,\n",
    "                                labels=b_labels)\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits   \n",
    "        # Accumulate the validation loss.\n",
    "        total_eval_loss += loss.item()\n",
    "        \n",
    "        # Move logits and labels to CPU\n",
    "        logits = (logits).detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "\n",
    "        # Calculate the number of correctly labeled examples in batch\n",
    "        pred_flat = np.argmax(logits, axis=1).flatten()\n",
    "        labels_flat = np.argmax(label_ids, axis=1).flatten()\n",
    "\n",
    "        num_correct = np.sum(pred_flat == labels_flat)\n",
    "        labels_incorrect = (pred_flat != labels_flat)\n",
    "        incorrect_values.append([pred_flat+1, labels_flat+1])\n",
    "        total_correct += num_correct\n",
    "        \n",
    "    # Report the final accuracy for this validation run.\n",
    "    print(\"Num of correct predictions =\", total_correct)\n",
    "    avg_val_accuracy = total_correct / len(val_set)\n",
    "\n",
    "    return avg_val_accuracy, incorrect_values[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 105609,
     "status": "ok",
     "timestamp": 1678919463348,
     "user": {
      "displayName": "Kruthay Reddy",
      "userId": "05785491489446510821"
     },
     "user_tz": 240
    },
    "id": "HTf_ipbjWNoV",
    "outputId": "f1c9542b-ae91-478f-f445-05ffea4cb5ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 7 ========\n",
      "Training...\n",
      "Total loss: 15.141500369205195\n",
      "Num of correct predictions = 7\n",
      "Validation accuracy: (0.1346153846153846, [array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), array([ 6, 13,  7,  1,  4,  2, 11, 13,  9,  8,  1,  2,  5, 12,  1, 13,  1,\n",
      "       13, 15,  5,  2, 12, 11,  4,  7, 13,  9,  1,  4,  9, 12,  7])])\n",
      "\n",
      "======== Epoch 2 / 7 ========\n",
      "Training...\n",
      "Total loss: 10.477692454923975\n",
      "Num of correct predictions = 7\n",
      "Validation accuracy: (0.1346153846153846, [array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), array([ 6, 13,  7,  1,  4,  2, 11, 13,  9,  8,  1,  2,  5, 12,  1, 13,  1,\n",
      "       13, 15,  5,  2, 12, 11,  4,  7, 13,  9,  1,  4,  9, 12,  7])])\n",
      "\n",
      "======== Epoch 3 / 7 ========\n",
      "Training...\n",
      "Total loss: 9.930332305583741\n",
      "Num of correct predictions = 21\n",
      "Validation accuracy: (0.40384615384615385, [array([12, 13,  7,  1, 11,  1,  3, 13,  2,  5,  1,  1,  5, 11, 13, 13,  1,\n",
      "       13,  3,  5,  7, 12, 13, 11,  7,  5,  7,  1,  3,  1, 12,  7]), array([ 6, 13,  7,  1,  4,  2, 11, 13,  9,  8,  1,  2,  5, 12,  1, 13,  1,\n",
      "       13, 15,  5,  2, 12, 11,  4,  7, 13,  9,  1,  4,  9, 12,  7])])\n",
      "\n",
      "======== Epoch 4 / 7 ========\n",
      "Training...\n",
      "Total loss: 8.540190468386813\n",
      "Num of correct predictions = 25\n",
      "Validation accuracy: (0.4807692307692308, [array([13, 13,  7,  1, 11,  1,  3, 13,  9,  5,  1,  7,  5, 15, 13, 13,  1,\n",
      "       13,  3,  5,  5, 12, 13, 11,  7,  5,  7,  1,  1,  9,  3,  7]), array([ 6, 13,  7,  1,  4,  2, 11, 13,  9,  8,  1,  2,  5, 12,  1, 13,  1,\n",
      "       13, 15,  5,  2, 12, 11,  4,  7, 13,  9,  1,  4,  9, 12,  7])])\n",
      "\n",
      "======== Epoch 5 / 7 ========\n",
      "Training...\n",
      "Total loss: 7.03721677763048\n",
      "Num of correct predictions = 29\n",
      "Validation accuracy: (0.5576923076923077, [array([13, 13,  7,  1, 15,  1,  3, 13,  9,  5,  1,  7,  3, 15, 13, 13,  1,\n",
      "       13,  3,  3,  2, 12, 13,  1,  7,  5,  7,  1,  1,  9, 12,  7]), array([ 6, 13,  7,  1,  4,  2, 11, 13,  9,  8,  1,  2,  5, 12,  1, 13,  1,\n",
      "       13, 15,  5,  2, 12, 11,  4,  7, 13,  9,  1,  4,  9, 12,  7])])\n",
      "\n",
      "======== Epoch 6 / 7 ========\n",
      "Training...\n",
      "Total loss: 5.664321168680909\n",
      "Num of correct predictions = 28\n",
      "Validation accuracy: (0.5384615384615384, [array([12, 13,  7,  1, 15,  1, 10, 13,  9,  5,  1,  7,  4, 15, 12, 13,  1,\n",
      "       12,  4,  4,  2, 12, 12, 12,  7,  6,  8,  1,  1,  9, 12,  5]), array([ 6, 13,  7,  1,  4,  2, 11, 13,  9,  8,  1,  2,  5, 12,  1, 13,  1,\n",
      "       13, 15,  5,  2, 12, 11,  4,  7, 13,  9,  1,  4,  9, 12,  7])])\n",
      "\n",
      "======== Epoch 7 / 7 ========\n",
      "Training...\n",
      "Total loss: 4.697938222007683\n",
      "Num of correct predictions = 26\n",
      "Validation accuracy: (0.5, [array([ 6, 13,  7,  1, 15,  2, 10, 13,  9,  5,  1,  7,  4, 15, 13, 13, 15,\n",
      "       12,  4,  4,  8, 12, 13, 11,  7,  6,  7,  1, 15,  9, 12,  7]), array([ 6, 13,  7,  1,  4,  2, 11, 13,  9,  8,  1,  2,  5, 12,  1, 13,  1,\n",
      "       13, 15,  5,  2, 12, 11,  4,  7, 13,  9,  1,  4,  9, 12,  7])])\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "for epoch_i in range(0, epochs):\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    total_train_loss = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    num_batches = int(len(train_set)/batch_size) + 1\n",
    "\n",
    "    for i in range(num_batches):\n",
    "      end_index = min(batch_size * (i+1), len(train_set))\n",
    "\n",
    "      batch = train_set[i*batch_size:end_index]\n",
    "\n",
    "      if len(batch) == 0: continue\n",
    "\n",
    "      input_id_tensors = torch.stack([data[0] for data in batch])\n",
    "      input_mask_tensors = torch.stack([data[1] for data in batch])\n",
    "      label_tensors = torch.stack([data[2] for data in batch])\n",
    "\n",
    "      b_input_ids = input_id_tensors.to(device)\n",
    "      b_input_mask = input_mask_tensors.to(device)\n",
    "      b_labels = label_tensors.to(device) \n",
    "\n",
    "      outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
    "      loss = outputs.loss\n",
    "      logits = outputs.logits\n",
    "\n",
    "      total_train_loss += loss.item()\n",
    "\n",
    "      model.zero_grad()     \n",
    "\n",
    "      loss.backward()\n",
    "\n",
    "      optimizer.step()\n",
    "        \n",
    "    print(f\"Total loss: {total_train_loss}\")\n",
    "    val_acc = validation(val_set)\n",
    "    print(f\"Validation accuracy: {val_acc}\")\n",
    "    \n",
    "print(\"\")\n",
    "print(\"Training complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 489,
     "status": "ok",
     "timestamp": 1678919463829,
     "user": {
      "displayName": "Kruthay Reddy",
      "userId": "05785491489446510821"
     },
     "user_tz": 240
    },
    "id": "msvZ78ii3cZZ",
    "outputId": "00d015ff-3ed8-4233-ac51-dd38641cf08d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of correct predictions = 22\n"
     ]
    }
   ],
   "source": [
    "Out = get_validation_performance(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1678919463829,
     "user": {
      "displayName": "Kruthay Reddy",
      "userId": "05785491489446510821"
     },
     "user_tz": 240
    },
    "id": "zJGO_VA681kO",
    "outputId": "feec0eb0-a73e-4452-80be-770c29bf946d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[15,  2,  9, 15,  6,  7, 15,  4,  3, 12, 13, 11,  9,  2,  7,  5,\n",
       "         7,  1,  6,  6, 13,  5,  3, 14,  7, 15,  7, 12,  9,  9, 13, 13],\n",
       "       [ 5,  1, 15, 15,  7,  9, 11,  1, 11,  4,  8,  4,  9, 12,  7,  5,\n",
       "         7,  1,  1,  4, 13,  5, 10,  5,  7,  1,  6,  4,  9, 10,  5,  4]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Labels = np.vstack(Out[1])\n",
    "Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wZoflscL86c6"
   },
   "source": [
    "The following is for creating the labels for the hidden dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1129,
     "status": "ok",
     "timestamp": 1678915113691,
     "user": {
      "displayName": "Kruthay Reddy",
      "userId": "05785491489446510821"
     },
     "user_tz": 240
    },
    "id": "X72mumhI9WdR",
    "outputId": "f66ea816-b8bc-43a9-fbc0-2376f96ea2ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excluded from the action will be some students and others with residency status, along with people applying for immigration status, such as those carrying \"green cards.\"\n",
      "Predicted Label : Crime and Punishment\n",
      "Acutal Label : Legality, Constitutionality, Jurisdiction\n",
      "*************************************\n",
      "The reasons for migration are important. Migrating for work purposes are different to migration to embark in higher education.\n",
      "Predicted Label : Capacity and Resources\n",
      "Acutal Label : Other\n",
      "*************************************\n",
      "Pakistani man arrested by FBI dies in jail cell\n",
      "Predicted Label : Crime and Punishment\n",
      "Acutal Label : Health and Safety\n",
      "*************************************\n",
      "IMMIGRANTS POUR INTO GEORGIA, HEARTLAND STATES, STUDY FINDS\n",
      "Predicted Label : Quality of Life\n",
      "Acutal Label : Cultural Identity\n",
      "*************************************\n",
      " but Ms. Trump said that the temporary plan was necessary for national security reasons.\n",
      "Predicted Label : Political\n",
      "Acutal Label : Security and Defense\n",
      "*************************************\n"
     ]
    }
   ],
   "source": [
    "## YOUR ERROR ANALYSIS CODE HERE\n",
    "listofLabels = [0, 3, 5, 6, 10 ]\n",
    "for i in listofLabels:\n",
    "  if Labels[0][i] != Labels[1][i]:\n",
    "    print(test_text[i])\n",
    "    print('Predicted Label :', res[Labels[0][i]])\n",
    "    print('Acutal Label :' ,res[Labels[1][i]] )\n",
    "    print('*************************************')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMBQw0pvU5qpBWZpMXkVM3C",
   "mount_file_id": "1xFgcX6YHIiWZWggMXsky2IZdJgaWw5i_",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "195b7adc0d48404983152b92b30e45c9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b3f3e14252604a8cba83f1f0baadae77",
      "placeholder": "​",
      "style": "IPY_MODEL_a4a42affa4894e29ab8a7b877d4f4482",
      "value": "Downloading pytorch_model.bin: 100%"
     }
    },
    "3b276e107e7b4b529eddde887626d9e0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "910bce19900f4576b4e2c828330bc14c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9803d2efa3d24145b5dcb92a0301cbe4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_195b7adc0d48404983152b92b30e45c9",
       "IPY_MODEL_cca5415315f34a19a0157289596fd009",
       "IPY_MODEL_cc6b7430b36c4fe59497a786f9b32aef"
      ],
      "layout": "IPY_MODEL_910bce19900f4576b4e2c828330bc14c"
     }
    },
    "a4a42affa4894e29ab8a7b877d4f4482": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "af94a1207256473cb226ba419c223ccb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b3f3e14252604a8cba83f1f0baadae77": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cc6b7430b36c4fe59497a786f9b32aef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fff9297d1c894764bf30a6b32f40b0d6",
      "placeholder": "​",
      "style": "IPY_MODEL_f5766afc8e7043d5a7bde77580d0e4ea",
      "value": " 672M/672M [00:07&lt;00:00, 95.2MB/s]"
     }
    },
    "cca5415315f34a19a0157289596fd009": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3b276e107e7b4b529eddde887626d9e0",
      "max": 672271273,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_af94a1207256473cb226ba419c223ccb",
      "value": 672271273
     }
    },
    "f5766afc8e7043d5a7bde77580d0e4ea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fff9297d1c894764bf30a6b32f40b0d6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
