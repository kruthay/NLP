{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 410,
     "status": "ok",
     "timestamp": 1678919272860,
     "user": {
      "displayName": "Kruthay Reddy",
      "userId": "05785491489446510821"
     },
     "user_tz": 240
    },
    "id": "c_0SdO4zK2Kq"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import sklearn\n",
    "from sklearn.metrics import cohen_kappa_score as kappa\n",
    "from sklearn.metrics import accuracy_score as accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 620,
     "status": "ok",
     "timestamp": 1678919273478,
     "user": {
      "displayName": "Kruthay Reddy",
      "userId": "05785491489446510821"
     },
     "user_tz": 240
    },
    "id": "UD7yvkwgy82S",
    "outputId": "13d10405-f193-4604-b629-17cc413f2e92"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/tt/mj79j1h50rz7ff5gs2htksmc0000gn/T/ipykernel_13056/3199717315.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m### WRITE CODE TO LOAD ANNOTATIONS AND\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Colab Notebooks/Data_Augumented_Train.tsv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtest1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Colab Notebooks/Augumented/Validtest_set.tsv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "### WRITE CODE TO LOAD ANNOTATIONS AND \n",
    "df = pd.read_table('/content/drive/MyDrive/Colab Notebooks/Data_Augumented_Train.tsv')\n",
    "test1 = pd.read_table('/content/drive/MyDrive/Colab Notebooks/Augumented/Validtest_set.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1678919273478,
     "user": {
      "displayName": "Kruthay Reddy",
      "userId": "05785491489446510821"
     },
     "user_tz": 240
    },
    "id": "edOh9ooiIW1B",
    "outputId": "b0a7de83-6c0f-471c-a0d5-165e8717681e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found device: Tesla T4, n_gpu: 1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Confirm that the GPU is detected\n",
    "\n",
    "assert torch.cuda.is_available()\n",
    "\n",
    "# Get the GPU device name.\n",
    "device_name = torch.cuda.get_device_name()\n",
    "n_gpu = torch.cuda.device_count()\n",
    "print(f\"Found device: {device_name}, n_gpu: {n_gpu}\")\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xrvH7xx9LnMC"
   },
   "source": [
    "## Installing Hugging Face's Transformers library\n",
    "We will use Hugging Face's Transformers (https://github.com/huggingface/transformers), an open-source library that provides general-purpose architectures for natural language understanding and generation with a collection of various pretrained models made by the NLP community."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8911,
     "status": "ok",
     "timestamp": 1678919282387,
     "user": {
      "displayName": "Kruthay Reddy",
      "userId": "05785491489446510821"
     },
     "user_tz": 240
    },
    "id": "gtqS2e5fxpqa",
    "outputId": "0b622c3b-7f72-4284-dacf-ce25f4933184"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (4.27.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.6.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install -U -q PyDrive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-8XIL7wPovVX"
   },
   "source": [
    "The cell below imports some helper functions we wrote to demonstrate the task on the sample seed dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1678919282388,
     "user": {
      "displayName": "Kruthay Reddy",
      "userId": "05785491489446510821"
     },
     "user_tz": 240
    },
    "id": "ZevgzNCcLmVO"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "from torch.utils.data import TensorDataset, random_split\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "import sys\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "def tokenize_and_format(sentences):\n",
    "  tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-uncased', do_lower_case=True)\n",
    "\n",
    "  # Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "  input_ids = []\n",
    "  attention_masks = []\n",
    "\n",
    "  # For every sentence...\n",
    "  for sentence in sentences:\n",
    "      # `encode_plus` will:\n",
    "      #   (1) Tokenize the sentence.\n",
    "      #   (2) Prepend the `[CLS]` token to the start.\n",
    "      #   (3) Append the `[SEP]` token to the end.\n",
    "      #   (4) Map tokens to their IDs.\n",
    "      #   (5) Pad or truncate the sentence to `max_length`\n",
    "      #   (6) Create attention masks for [PAD] tokens.\n",
    "      encoded_dict = tokenizer.encode_plus(\n",
    "                          sentence,                      # Sentence to encode.\n",
    "                          add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                          max_length = 64,           # Pad & truncate all sentences.\n",
    "                          padding = 'max_length',\n",
    "                          truncation = True,\n",
    "                          return_attention_mask = True,   # Construct attn. masks.\n",
    "                          return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                    )\n",
    "\n",
    "      # Add the encoded sentence to the list.\n",
    "      input_ids.append(encoded_dict['input_ids'])\n",
    "\n",
    "      # And its attention mask (simply differentiates padding from non-padding).\n",
    "      attention_masks.append(encoded_dict['attention_mask'])\n",
    "  return input_ids, attention_masks\n",
    "\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1678919282388,
     "user": {
      "displayName": "Kruthay Reddy",
      "userId": "05785491489446510821"
     },
     "user_tz": 240
    },
    "id": "x4GtJiNCLl8t",
    "outputId": "2a0aaf9d-89c0-4611-d34a-16ba8bb811f5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-16-941db2e15420>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test3.sentence[100] = 'Even Arabs with no alleged link to the Sept. 11 attacks, such as former USF instructor Mazen Al-Najjar and suspended professor Sami Al-Arian, have been caught up in that wave, he said. \"We have not sacrificed our own liberties but the liberties of immigrants,\" said Cole, who helped represent Al-Najjar during his ongoing battles with the Immigration and Naturalization Service. Al-Najjar is currently in prison.'\n"
     ]
    }
   ],
   "source": [
    "test3.sentence[100] = 'Even Arabs with no alleged link to the Sept. 11 attacks, such as former USF instructor Mazen Al-Najjar and suspended professor Sami Al-Arian, have been caught up in that wave, he said. \"We have not sacrificed our own liberties but the liberties of immigrants,\" said Cole, who helped represent Al-Najjar during his ongoing battles with the Immigration and Naturalization Service. Al-Najjar is currently in prison.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gKc0xYh-MAbc"
   },
   "source": [
    "# Part 1: Data Prep and Model Specifications\n",
    "\n",
    "Upload your data using the file explorer to the left. We have provided a function below to tokenize and format your data as BERT requires. Make sure that your tsv file, titled final_data.tsv, has one column \"sentence\" and another column \"labels_ID\" containing integers/float.\n",
    "\n",
    "If you run the cell below without modifications, it will run on the seed.tsv example data we have provided. It imports some helper functions we wrote to demonstrate the task on the sample dataset. You should first run all of the following cells with seed.tsv just to see how everything works. Then, once you understand the whole preprocessing / fine-tuning process, change the tsv in the below cell to your final_data.tsv file, add any extra preprocessing code you wish, and then run the cells again on your own data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 53979,
     "status": "ok",
     "timestamp": 1678919336363,
     "user": {
      "displayName": "Kruthay Reddy",
      "userId": "05785491489446510821"
     },
     "user_tz": 240
    },
    "id": "YGhkeLQlNNr8",
    "outputId": "23234d22-8c5c-42e0-eb20-d0c41b6b502b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  Good access to health care is associated with fewer deaths.\n",
      "Token IDs: tensor([  101, 12050, 16488, 10114, 13347, 11258, 10127, 16350, 10171, 68367,\n",
      "        44887,   119,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#df = pd.read_csv('final_data.tsv')\n",
    "#df = pd.read_csv('/content/drive/MyDrive/seed.tsv')\n",
    "\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "texts = df.sentence.values\n",
    "labels = df.label_ID.values\n",
    "labels2 = df.label_ID2.values\n",
    "texts_test = test1.sentence.values\n",
    "labels_test = test1.label_ID.values\n",
    "\n",
    "texts_test2 = test2.sentence.values\n",
    "labels_test2 = test2.label_ID.values\n",
    "\n",
    "texts_json = tdf.sentence.values\n",
    "\n",
    "### tokenize_and_format() is a helper function provided in helpers.py ###\n",
    "input_ids, attention_masks = tokenize_and_format(texts)\n",
    "input_ids_test, attention_masks_test = tokenize_and_format(texts_test)\n",
    "\n",
    "input_ids_test2, attention_masks_test2 = tokenize_and_format(texts_test2)\n",
    "input_ids_json, attention_masks_json = tokenize_and_format(texts_json)\n",
    "\n",
    "\n",
    "label_list = []\n",
    "for l,m in zip(labels, labels2):\n",
    "  label_array = np.zeros(len(set(labels)))\n",
    "  label_array[int(l)-1] += 0.5\n",
    "  label_array[int(m)-1] += 0.5\n",
    "  label_list.append(label_array)\n",
    "\n",
    "#for Test Labels\n",
    "label_list_test = []\n",
    "for l in labels_test:\n",
    "  label_array = np.zeros(len(set(labels)))\n",
    "  label_array[int(l)-1] = 1\n",
    "  label_list_test.append(label_array)\n",
    "\n",
    "label_list_test2 = []\n",
    "for l in labels_test2:\n",
    "  label_array = np.zeros(len(set(labels)))\n",
    "  label_array[int(l)-1] = 1\n",
    "  label_list_test2.append(label_array)\n",
    "\n",
    "\n",
    "\n",
    "# Convert the lists into tensors.\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(np.array(label_list))\n",
    "\n",
    "# Convert the lists into tensors.\n",
    "input_ids_test = torch.cat(input_ids_test, dim=0)\n",
    "attention_masks_test = torch.cat(attention_masks_test, dim=0)\n",
    "labels_test = torch.tensor(np.array(label_list_test))\n",
    "\n",
    "# Convert the lists into tensors.\n",
    "input_ids_test2 = torch.cat(input_ids_test2, dim=0)\n",
    "attention_masks_test2 = torch.cat(attention_masks_test2, dim=0)\n",
    "labels_test2 = torch.tensor(np.array(label_list_test2))\n",
    "\n",
    "\n",
    "\n",
    "input_ids_json = torch.cat(input_ids_json, dim=0)\n",
    "attention_masks_json = torch.cat(attention_masks_json, dim=0)\n",
    "\n",
    "\n",
    "# Print sentence 0, now as a list of IDs.\n",
    "print('Original: ', texts[0])\n",
    "print('Token IDs:', input_ids[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H3D-CzQEUXYz"
   },
   "source": [
    "## Create train/test/validation splits\n",
    "\n",
    "Here we split your dataset into 3 parts: a training set, a validation set, and a testing set. Each item in your dataset will be a 3-tuple containing an input_id tensor, an attention_mask tensor, and a label tensor.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1678919336363,
     "user": {
      "displayName": "Kruthay Reddy",
      "userId": "05785491489446510821"
     },
     "user_tz": 240
    },
    "id": "kGgeZ3M0UWs0"
   },
   "outputs": [],
   "source": [
    "\n",
    "total = len(test1)\n",
    "\n",
    "num_train = len(df)\n",
    "num_val = int(total * .5)\n",
    "num_test = total - num_val\n",
    "\n",
    "# make lists of 3-tuples (already shuffled the dataframe in cell above)\n",
    "\n",
    "train_set = [(input_ids[i], attention_masks[i], labels[i]) for i in range(num_train)]\n",
    "val_set = [(input_ids_test[i], attention_masks_test[i], labels_test[i]) for i in range(num_val)]\n",
    "test_set = [(input_ids_test[i], attention_masks_test[i], labels_test[i]) for i in range(num_val, total)]\n",
    "val_set2 = [(input_ids_test2[i], attention_masks_test2[i], labels_test2[i]) for i in range(num_val)]\n",
    "test_set2 = [(input_ids_test2[i], attention_masks_test2[i], labels_test2[i]) for i in range(num_val, total)]\n",
    "\n",
    "json_set = [(input_ids_json[i], attention_masks_json[i]) for i in range(0, len(tdf))]\n",
    "\n",
    "train_text = [texts[i] for i in range(num_train)]\n",
    "val_text = [texts_test[i] for i in range(num_val)]\n",
    "test_text = [texts_test[i] for i in range(num_val, total)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QCr006iTkqwM"
   },
   "source": [
    "Here we choose the model we want to finetune from https://huggingface.co/transformers/pretrained_models.html. Because the task requires us to label sentences, we wil be using BertForSequenceClassification below. You may see a warning that states that `some weights of the model checkpoint at [model name] were not used when initializing. . .` This warning is expected and means that you should fine-tune your pre-trained model before using it on your downstream task. See [here](https://github.com/huggingface/transformers/issues/5421#issuecomment-652582854) for more info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 176,
     "referenced_widgets": [
      "9803d2efa3d24145b5dcb92a0301cbe4",
      "195b7adc0d48404983152b92b30e45c9",
      "cca5415315f34a19a0157289596fd009",
      "cc6b7430b36c4fe59497a786f9b32aef",
      "910bce19900f4576b4e2c828330bc14c",
      "b3f3e14252604a8cba83f1f0baadae77",
      "a4a42affa4894e29ab8a7b877d4f4482",
      "3b276e107e7b4b529eddde887626d9e0",
      "af94a1207256473cb226ba419c223ccb",
      "fff9297d1c894764bf30a6b32f40b0d6",
      "f5766afc8e7043d5a7bde77580d0e4ea"
     ]
    },
    "executionInfo": {
     "elapsed": 21399,
     "status": "ok",
     "timestamp": 1678919357756,
     "user": {
      "displayName": "Kruthay Reddy",
      "userId": "05785491489446510821"
     },
     "user_tz": 240
    },
    "id": "lPo640_ZlEPK",
    "outputId": "04d5b9f2-398d-4bf8-d779-0a77ce96f66b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9803d2efa3d24145b5dcb92a0301cbe4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/672M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-multilingual-uncased\", # Use the 12-layer English BERT model, with an uncased vocab.\n",
    "    num_labels = 15, # The number of output labels.   \n",
    "    output_attentions = False, # Whether the model returns attentions weights.\n",
    "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
    ")\n",
    "\n",
    "model.config.hidden_dropout_prob = 0.2\n",
    "\n",
    "# Tell pytorch to run this model on the GPU.\n",
    "model.cuda()\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i3lLdoW_le3M"
   },
   "source": [
    "# ACTION REQUIRED #\n",
    "\n",
    "Define your fine-tuning hyperparameters in the cell below (we have randomly picked some values to start with). We want you to experiment with different configurations to find the one that works best (i.e., highest accuracy) on your validation set. Feel free to also change pretrained models to others available in the HuggingFace library (you'll have to modify the cell above to do this). You might find papers on BERT fine-tuning stability (e.g., [Mosbach et al., ICLR 2021](https://openreview.net/pdf?id=nzpLWnVAyah)) to be of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1678919357757,
     "user": {
      "displayName": "Kruthay Reddy",
      "userId": "05785491489446510821"
     },
     "user_tz": 240
    },
    "id": "Dd2JdC6IletV",
    "outputId": "4cb2cfcd-84aa-4204-be7a-5c28198943bb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_size = 32\n",
    "optimizer = AdamW(model.parameters(), lr = 5e-5) #with default values of learning rate and epsilon value\n",
    "epochs = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xkPaGaKVlirF"
   },
   "source": [
    "batch_size = 32\n",
    "optimizer = AdamW(model.parameters(), lr = 6e-5) #with default values of learning rate and epsilon value\n",
    "epochs = 5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pd4fwn_el1ge"
   },
   "source": [
    "# Fine-tune your model\n",
    "Here we provide code for fine-tuning your model, monitoring the loss, and checking your validation accuracy. Rerun both of the below cells when you change your hyperparameters above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1678919357757,
     "user": {
      "displayName": "Kruthay Reddy",
      "userId": "05785491489446510821"
     },
     "user_tz": 240
    },
    "id": "O_Mzr-kd5RaY"
   },
   "outputs": [],
   "source": [
    "# function to get validation accuracy\n",
    "def get_validation_performance(val_set):\n",
    "    # Put the model in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables \n",
    "    total_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "\n",
    "    num_batches = int(len(val_set)/batch_size) + 1\n",
    "\n",
    "    total_correct = 0\n",
    "    incorrect_values = []\n",
    "    for i in range(num_batches):\n",
    "\n",
    "      end_index = min(batch_size * (i+1), len(val_set))\n",
    "\n",
    "      batch = val_set[i*batch_size:end_index]\n",
    "      \n",
    "      if len(batch) == 0: continue\n",
    "\n",
    "      input_id_tensors = torch.stack([data[0] for data in batch])\n",
    "      input_mask_tensors = torch.stack([data[1] for data in batch])\n",
    "      label_tensors = torch.stack([data[2] for data in batch])\n",
    "      \n",
    "      # Move tensors to the GPU\n",
    "      b_input_ids = input_id_tensors.to(device)\n",
    "      b_input_mask = input_mask_tensors.to(device)\n",
    "      b_labels = label_tensors.to(device)\n",
    "        \n",
    "      # Tell pytorch not to bother with constructing the compute graph during\n",
    "      # the forward pass, since this is only needed for backprop (training).\n",
    "      with torch.no_grad():        \n",
    "\n",
    "        # Forward pass, calculate logit predictions.\n",
    "        outputs = model(b_input_ids, \n",
    "                                token_type_ids=None, \n",
    "                                attention_mask=b_input_mask,\n",
    "                                labels=b_labels)\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits   \n",
    "        # Accumulate the validation loss.\n",
    "        total_eval_loss += loss.item()\n",
    "        \n",
    "        # Move logits and labels to CPU\n",
    "        logits = (logits).detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "\n",
    "        # Calculate the number of correctly labeled examples in batch\n",
    "        pred_flat = np.argmax(logits, axis=1).flatten()\n",
    "        labels_flat = np.argmax(label_ids, axis=1).flatten()\n",
    "\n",
    "        num_correct = np.sum(pred_flat == labels_flat)\n",
    "        labels_incorrect = (pred_flat != labels_flat)\n",
    "        incorrect_values.append([pred_flat+1, labels_flat+1])\n",
    "        total_correct += num_correct\n",
    "        \n",
    "    # Report the final accuracy for this validation run.\n",
    "    print(\"Num of correct predictions =\", total_correct)\n",
    "    avg_val_accuracy = total_correct / len(val_set)\n",
    "\n",
    "    return avg_val_accuracy, incorrect_values[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 105609,
     "status": "ok",
     "timestamp": 1678919463348,
     "user": {
      "displayName": "Kruthay Reddy",
      "userId": "05785491489446510821"
     },
     "user_tz": 240
    },
    "id": "HTf_ipbjWNoV",
    "outputId": "f1c9542b-ae91-478f-f445-05ffea4cb5ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 7 ========\n",
      "Training...\n",
      "Total loss: 15.141500369205195\n",
      "Num of correct predictions = 7\n",
      "Validation accuracy: (0.1346153846153846, [array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), array([ 6, 13,  7,  1,  4,  2, 11, 13,  9,  8,  1,  2,  5, 12,  1, 13,  1,\n",
      "       13, 15,  5,  2, 12, 11,  4,  7, 13,  9,  1,  4,  9, 12,  7])])\n",
      "\n",
      "======== Epoch 2 / 7 ========\n",
      "Training...\n",
      "Total loss: 10.477692454923975\n",
      "Num of correct predictions = 7\n",
      "Validation accuracy: (0.1346153846153846, [array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), array([ 6, 13,  7,  1,  4,  2, 11, 13,  9,  8,  1,  2,  5, 12,  1, 13,  1,\n",
      "       13, 15,  5,  2, 12, 11,  4,  7, 13,  9,  1,  4,  9, 12,  7])])\n",
      "\n",
      "======== Epoch 3 / 7 ========\n",
      "Training...\n",
      "Total loss: 9.930332305583741\n",
      "Num of correct predictions = 21\n",
      "Validation accuracy: (0.40384615384615385, [array([12, 13,  7,  1, 11,  1,  3, 13,  2,  5,  1,  1,  5, 11, 13, 13,  1,\n",
      "       13,  3,  5,  7, 12, 13, 11,  7,  5,  7,  1,  3,  1, 12,  7]), array([ 6, 13,  7,  1,  4,  2, 11, 13,  9,  8,  1,  2,  5, 12,  1, 13,  1,\n",
      "       13, 15,  5,  2, 12, 11,  4,  7, 13,  9,  1,  4,  9, 12,  7])])\n",
      "\n",
      "======== Epoch 4 / 7 ========\n",
      "Training...\n",
      "Total loss: 8.540190468386813\n",
      "Num of correct predictions = 25\n",
      "Validation accuracy: (0.4807692307692308, [array([13, 13,  7,  1, 11,  1,  3, 13,  9,  5,  1,  7,  5, 15, 13, 13,  1,\n",
      "       13,  3,  5,  5, 12, 13, 11,  7,  5,  7,  1,  1,  9,  3,  7]), array([ 6, 13,  7,  1,  4,  2, 11, 13,  9,  8,  1,  2,  5, 12,  1, 13,  1,\n",
      "       13, 15,  5,  2, 12, 11,  4,  7, 13,  9,  1,  4,  9, 12,  7])])\n",
      "\n",
      "======== Epoch 5 / 7 ========\n",
      "Training...\n",
      "Total loss: 7.03721677763048\n",
      "Num of correct predictions = 29\n",
      "Validation accuracy: (0.5576923076923077, [array([13, 13,  7,  1, 15,  1,  3, 13,  9,  5,  1,  7,  3, 15, 13, 13,  1,\n",
      "       13,  3,  3,  2, 12, 13,  1,  7,  5,  7,  1,  1,  9, 12,  7]), array([ 6, 13,  7,  1,  4,  2, 11, 13,  9,  8,  1,  2,  5, 12,  1, 13,  1,\n",
      "       13, 15,  5,  2, 12, 11,  4,  7, 13,  9,  1,  4,  9, 12,  7])])\n",
      "\n",
      "======== Epoch 6 / 7 ========\n",
      "Training...\n",
      "Total loss: 5.664321168680909\n",
      "Num of correct predictions = 28\n",
      "Validation accuracy: (0.5384615384615384, [array([12, 13,  7,  1, 15,  1, 10, 13,  9,  5,  1,  7,  4, 15, 12, 13,  1,\n",
      "       12,  4,  4,  2, 12, 12, 12,  7,  6,  8,  1,  1,  9, 12,  5]), array([ 6, 13,  7,  1,  4,  2, 11, 13,  9,  8,  1,  2,  5, 12,  1, 13,  1,\n",
      "       13, 15,  5,  2, 12, 11,  4,  7, 13,  9,  1,  4,  9, 12,  7])])\n",
      "\n",
      "======== Epoch 7 / 7 ========\n",
      "Training...\n",
      "Total loss: 4.697938222007683\n",
      "Num of correct predictions = 26\n",
      "Validation accuracy: (0.5, [array([ 6, 13,  7,  1, 15,  2, 10, 13,  9,  5,  1,  7,  4, 15, 13, 13, 15,\n",
      "       12,  4,  4,  8, 12, 13, 11,  7,  6,  7,  1, 15,  9, 12,  7]), array([ 6, 13,  7,  1,  4,  2, 11, 13,  9,  8,  1,  2,  5, 12,  1, 13,  1,\n",
      "       13, 15,  5,  2, 12, 11,  4,  7, 13,  9,  1,  4,  9, 12,  7])])\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# training loop\n",
    "\n",
    "# For each epoch...\n",
    "for epoch_i in range(0, epochs):\n",
    "    # Perform one full pass over the training set.\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_train_loss = 0\n",
    "\n",
    "    # Put the model into training mode.\n",
    "    model.train()\n",
    "\n",
    "    # For each batch of training data...\n",
    "    num_batches = int(len(train_set)/batch_size) + 1\n",
    "\n",
    "    for i in range(num_batches):\n",
    "      end_index = min(batch_size * (i+1), len(train_set))\n",
    "\n",
    "      batch = train_set[i*batch_size:end_index]\n",
    "\n",
    "      if len(batch) == 0: continue\n",
    "\n",
    "      input_id_tensors = torch.stack([data[0] for data in batch])\n",
    "      input_mask_tensors = torch.stack([data[1] for data in batch])\n",
    "      label_tensors = torch.stack([data[2] for data in batch])\n",
    "\n",
    "      # Move tensors to the GPU\n",
    "      b_input_ids = input_id_tensors.to(device)\n",
    "      b_input_mask = input_mask_tensors.to(device)\n",
    "      b_labels = label_tensors.to(device) \n",
    "\n",
    "      # Perform a forward pass (evaluate the model on this training batch).\n",
    "      outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
    "      loss = outputs.loss\n",
    "      logits = outputs.logits\n",
    "\n",
    "      total_train_loss += loss.item()\n",
    "\n",
    "      # Clear the previously calculated gradient\n",
    "      model.zero_grad()     \n",
    "\n",
    "      # Perform a backward pass to calculate the gradients.\n",
    "      loss.backward()\n",
    "\n",
    "      # Update parameters and take a step using the computed gradient.\n",
    "      optimizer.step()\n",
    "        \n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set. Implement this function in the cell above.\n",
    "    print(f\"Total loss: {total_train_loss}\")\n",
    "    val_acc = get_validation_performance(val_set)\n",
    "    print(f\"Validation accuracy: {val_acc}\")\n",
    "    \n",
    "print(\"\")\n",
    "print(\"Training complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J9DpRJE5mHkO"
   },
   "source": [
    "# Evaluate your model on the test set\n",
    "After you're satisfied with your hyperparameters (i.e., you're unable to achieve higher validation accuracy by modifying them further), it's time to evaluate your model on the test set! Run the below cell to compute test set accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1678919463348,
     "user": {
      "displayName": "Kruthay Reddy",
      "userId": "05785491489446510821"
     },
     "user_tz": 240
    },
    "id": "LCZdKYutuFwe"
   },
   "outputs": [],
   "source": [
    "# function to get validation accuracy\n",
    "def get_test_performance(val_set):\n",
    "    # Put the model in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables \n",
    "    total_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "\n",
    "    num_batches = int(len(val_set)/batch_size) + 1\n",
    "\n",
    "    total_correct = 0\n",
    "\n",
    "    predictions = []\n",
    "\n",
    "    for i in range(num_batches):\n",
    "\n",
    "      end_index = min(batch_size * (i+1), len(val_set))\n",
    "\n",
    "      batch = val_set[i*batch_size:end_index]\n",
    "      \n",
    "      if len(batch) == 0: continue\n",
    "\n",
    "      input_id_tensors = torch.stack([data[0] for data in batch])\n",
    "\n",
    "      # Move tensors to the GPU\n",
    "      b_input_ids = input_id_tensors.to(device)\n",
    "        \n",
    "      # Tell pytorch not to bother with constructing the compute graph during\n",
    "      # the forward pass, since this is only needed for backprop (training).\n",
    "      with torch.no_grad():        \n",
    "\n",
    "        # Forward pass, calculate logit predictions.\n",
    "        outputs = model(b_input_ids)\n",
    "        logits = outputs.logits   \n",
    "        \n",
    "        # Move logits and labels to CPU\n",
    "        logits = (logits).detach().cpu().numpy()\n",
    "\n",
    "\n",
    "        # Calculate the number of correctly labeled examples in batch\n",
    "        pred_flat = np.argmax(logits, axis=1).flatten()\n",
    "\n",
    "        predictions.append(pred_flat)\n",
    "\n",
    "        \n",
    "    # Report the final accuracy for this validation run.\n",
    "    print(\"Num of correct predictions =\", total_correct)\n",
    "    return predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 489,
     "status": "ok",
     "timestamp": 1678919463829,
     "user": {
      "displayName": "Kruthay Reddy",
      "userId": "05785491489446510821"
     },
     "user_tz": 240
    },
    "id": "msvZ78ii3cZZ",
    "outputId": "00d015ff-3ed8-4233-ac51-dd38641cf08d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of correct predictions = 22\n"
     ]
    }
   ],
   "source": [
    "Out = get_validation_performance(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1678919463829,
     "user": {
      "displayName": "Kruthay Reddy",
      "userId": "05785491489446510821"
     },
     "user_tz": 240
    },
    "id": "zJGO_VA681kO",
    "outputId": "feec0eb0-a73e-4452-80be-770c29bf946d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[15,  2,  9, 15,  6,  7, 15,  4,  3, 12, 13, 11,  9,  2,  7,  5,\n",
       "         7,  1,  6,  6, 13,  5,  3, 14,  7, 15,  7, 12,  9,  9, 13, 13],\n",
       "       [ 5,  1, 15, 15,  7,  9, 11,  1, 11,  4,  8,  4,  9, 12,  7,  5,\n",
       "         7,  1,  1,  4, 13,  5, 10,  5,  7,  1,  6,  4,  9, 10,  5,  4]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Labels = np.vstack(Out[1])\n",
    "Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wZoflscL86c6"
   },
   "source": [
    "The following is for creating the labels for the hidden dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 129239,
     "status": "ok",
     "timestamp": 1678919593066,
     "user": {
      "displayName": "Kruthay Reddy",
      "userId": "05785491489446510821"
     },
     "user_tz": 240
    },
    "id": "YiGRcRoaE2kw",
    "outputId": "315bfee2-cd96-4f16-e460-10833d27a1c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of correct predictions = 0\n"
     ]
    }
   ],
   "source": [
    "output = get_test_performance(json_set)\n",
    "flatten = np.concatenate(output) + 1\n",
    "flatten = np.float64(flatten)\n",
    "tdf['label_ID'] = flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1678919593066,
     "user": {
      "displayName": "Kruthay Reddy",
      "userId": "05785491489446510821"
     },
     "user_tz": 240
    },
    "id": "zQnPv_1NAt6R"
   },
   "outputs": [],
   "source": [
    "mapping = {'Economic': '1.0',\n",
    " 'Capacity and Resources': '2.0',\n",
    " 'Morality': '3.0',\n",
    " 'Fairness and Equality': '4.0',\n",
    " 'Legality, Constitutionality, Jurisdiction': '5.0',\n",
    " 'Policy Prescription and Evaluation': '6.0',\n",
    " 'Crime and Punishment': '7.0',\n",
    " 'Security and Defense': '8.0',\n",
    " 'Health and Safety': '9.0',\n",
    " 'Quality of Life': '10.0',\n",
    " 'Cultural Identity': '11.0',\n",
    " 'Public Sentiment': '12.0',\n",
    " 'Political': '13.0',\n",
    " 'External Regulation and Reputation': '14.0',\n",
    " 'Other': '15.0'}\n",
    "res = dict((float(v),k) for k,v in mapping.items())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sHWAbSP85-b3"
   },
   "outputs": [],
   "source": [
    "tdf['predicted_label'] = tdf['label_ID'].map(res)\n",
    "tdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ps0v6yUzQUFZ"
   },
   "outputs": [],
   "source": [
    "for i in mapping.keys():\n",
    "  print(i, tdf[tdf.predicted_label == i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FeGfRj4NOWTd"
   },
   "outputs": [],
   "source": [
    "tdf.to_csv('/content/drive/MyDrive/JsonTests.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Om5ZaS-k2GMJ"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "tdf.to_json('/content/drive/MyDrive/result.json',orient=\"records\", force_ascii = False, indent = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NBbdMwt79fIs"
   },
   "source": [
    "## Question 2.2 (10 points):\n",
    "Finally, perform an *error analysis* on your model. This is good practice for your final project. Write some code in the below code cell to print out the text of up to five test set examples that your model gets **wrong**. If your model gets more than five test examples wrong, randomly choose five of them to analyze. If your model gets fewer than five examples wrong, please design five test examples that fool your model (i.e., *adversarial examples*). Then, in the following text cell, perform a qualitative analysis of these examples. See if you can figure out any reasons for errors that you observe, or if you have any informed guesses (e.g., common linguistic properties of these particular examples). Does this analysis suggest any possible future steps to improve your classifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1129,
     "status": "ok",
     "timestamp": 1678915113691,
     "user": {
      "displayName": "Kruthay Reddy",
      "userId": "05785491489446510821"
     },
     "user_tz": 240
    },
    "id": "X72mumhI9WdR",
    "outputId": "f66ea816-b8bc-43a9-fbc0-2376f96ea2ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excluded from the action will be some students and others with residency status, along with people applying for immigration status, such as those carrying \"green cards.\"\n",
      "Predicted Label : Crime and Punishment\n",
      "Acutal Label : Legality, Constitutionality, Jurisdiction\n",
      "*************************************\n",
      "The reasons for migration are important. Migrating for work purposes are different to migration to embark in higher education.\n",
      "Predicted Label : Capacity and Resources\n",
      "Acutal Label : Other\n",
      "*************************************\n",
      "Pakistani man arrested by FBI dies in jail cell\n",
      "Predicted Label : Crime and Punishment\n",
      "Acutal Label : Health and Safety\n",
      "*************************************\n",
      "IMMIGRANTS POUR INTO GEORGIA, HEARTLAND STATES, STUDY FINDS\n",
      "Predicted Label : Quality of Life\n",
      "Acutal Label : Cultural Identity\n",
      "*************************************\n",
      " but Ms. Trump said that the temporary plan was necessary for national security reasons.\n",
      "Predicted Label : Political\n",
      "Acutal Label : Security and Defense\n",
      "*************************************\n"
     ]
    }
   ],
   "source": [
    "## YOUR ERROR ANALYSIS CODE HERE\n",
    "listofLabels = [0, 3, 5, 6, 10 ]\n",
    "for i in listofLabels:\n",
    "  if Labels[0][i] != Labels[1][i]:\n",
    "    print(test_text[i])\n",
    "    print('Predicted Label :', res[Labels[0][i]])\n",
    "    print('Acutal Label :' ,res[Labels[1][i]] )\n",
    "    print('*************************************')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EO2PvsNZI9EH"
   },
   "source": [
    "I think the reason model failed to predict some of these texts is linguistic and subjectiveness of the labels. \n",
    "1. In the first text, the model predicted \"Crime and Punishment\" by considering \"Excluded from the action\"\n",
    "\n",
    "2.  In the second text, Migrating for work purposes, might have made model to choose \"Capacity and Resources\"\n",
    "\n",
    "3. In the third text, it's annotated wrongly and the model actually predicted it correct.\n",
    "\n",
    "4. In the fourth text, The label is more subjective, \n",
    "\n",
    "5. In the fifth text, The word \"Trump\" may have made model to choose \"Political\"\n",
    "\n",
    "\n",
    "I think if more agreed annotated data is provided the model could perform much better. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6XyBdAup-e6Z"
   },
   "source": [
    "### *DESCRIBE YOUR QUALITATIVE ANALYSIS OF THE ABOVE EXAMPLES IN YOUR REPORT*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "szIkBDiQ_Mkv"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "Finished? Remember to upload the PDF file of this notebook, report and your three dataset files (annotator1.tsv, annotator2.tsv, and final_data.tsv) to Gradescope with the filename line formatted as **Firstname_Lastname_HW2**.\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMBQw0pvU5qpBWZpMXkVM3C",
   "mount_file_id": "1xFgcX6YHIiWZWggMXsky2IZdJgaWw5i_",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "195b7adc0d48404983152b92b30e45c9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b3f3e14252604a8cba83f1f0baadae77",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_a4a42affa4894e29ab8a7b877d4f4482",
      "value": "Downloading pytorch_model.bin: 100%"
     }
    },
    "3b276e107e7b4b529eddde887626d9e0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "910bce19900f4576b4e2c828330bc14c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9803d2efa3d24145b5dcb92a0301cbe4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_195b7adc0d48404983152b92b30e45c9",
       "IPY_MODEL_cca5415315f34a19a0157289596fd009",
       "IPY_MODEL_cc6b7430b36c4fe59497a786f9b32aef"
      ],
      "layout": "IPY_MODEL_910bce19900f4576b4e2c828330bc14c"
     }
    },
    "a4a42affa4894e29ab8a7b877d4f4482": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "af94a1207256473cb226ba419c223ccb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b3f3e14252604a8cba83f1f0baadae77": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cc6b7430b36c4fe59497a786f9b32aef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fff9297d1c894764bf30a6b32f40b0d6",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_f5766afc8e7043d5a7bde77580d0e4ea",
      "value": " 672M/672M [00:07&lt;00:00, 95.2MB/s]"
     }
    },
    "cca5415315f34a19a0157289596fd009": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3b276e107e7b4b529eddde887626d9e0",
      "max": 672271273,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_af94a1207256473cb226ba419c223ccb",
      "value": 672271273
     }
    },
    "f5766afc8e7043d5a7bde77580d0e4ea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fff9297d1c894764bf30a6b32f40b0d6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
